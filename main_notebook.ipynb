{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VQMOv428DfA",
        "outputId": "b89dad16-1285-4d37-fd19-0ad53300c099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5bXIvsnVQm0v"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep_learning_quantized')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import architectures\n",
        "import network_training\n",
        "import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F0GDzAhFrvHV"
      },
      "outputs": [],
      "source": [
        "def read_data_from_csv(csv_file_name):\n",
        "      data = pd.read_csv(csv_file_name)\n",
        "      x_data = data.iloc[:, :-2].values\n",
        "      y_data = data.iloc[:, -2].values\n",
        "      subj = data.iloc[:, -1].values\n",
        "\n",
        "      return x_data, y_data, subj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eCyTR0urJoJw"
      },
      "outputs": [],
      "source": [
        "csv_file_name = '/content/drive/MyDrive/deep_learning_quantized/multimodal_data.csv'\n",
        "labels = ('low', 'medium', 'high')\n",
        "avg = True\n",
        "\n",
        "features, targets, subj_data = read_data_from_csv(csv_file_name)\n",
        "fs = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0delxoDwp0D",
        "outputId": "78008120-f2c3-461e-ffe1-e1056cfb1e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -18.68]\n",
            " [ -17.01]\n",
            " [ -14.2 ]\n",
            " ...\n",
            " [-116.5 ]\n",
            " [-116.5 ]\n",
            " [-113.31]]\n"
          ]
        }
      ],
      "source": [
        "# features = features[:, 0:4]\n",
        "features = features[:, 0].reshape(-1, 1)\n",
        "# features = features[:, 1:4]\n",
        "\n",
        "# features = features[:, 5].reshape(-1, 1)\n",
        "# features = features[:, 6:9]\n",
        "\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wTv6Q3Ubawlw"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"seed\" : 256,\n",
        "    \"learning_rate\" : 0.005,\n",
        "    \"weight_decay\" : 1e-6,\n",
        "    \"step_size\" : 3,\n",
        "    \"gamma\" : 0.85,\n",
        "    \"batch_size\" : 128,\n",
        "    \"epochs\" : 30,\n",
        "    \"num_resblocks\" : 3,\n",
        "    \"resblock_id\" : 0\n",
        "}\n",
        "\n",
        "params[\"window_size\"] = fs * 8\n",
        "params[\"overlap\"] = params[\"window_size\"] * 7//8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzwYFHnv_J4I",
        "outputId": "a6ba66e0-fce8-41ed-95ef-b3653e6cf9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40757, 512, 1) (40757,)\n"
          ]
        }
      ],
      "source": [
        "scaled_data = preprocessing.scale_data(features, targets)\n",
        "\n",
        "sliding_X_data, sliding_y_data = preprocessing.apply_sliding_window(scaled_data, targets, subj_data, params[\"window_size\"], params[\"overlap\"], avg)\n",
        "\n",
        "X_data = sliding_X_data.astype(np.float32)\n",
        "y_data = sliding_y_data.astype(np.uint8)\n",
        "\n",
        "print(X_data.shape, y_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ItuhNLcn_3VR"
      },
      "outputs": [],
      "source": [
        "params[\"num_channels\"] = X_data.shape[2]\n",
        "params[\"num_classes\"] = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DiWkLZ7P7ZBP"
      },
      "outputs": [],
      "source": [
        "import keras.utils\n",
        "\n",
        "X_train, X_test, y_train, y_test = network_training.split_data(X_data, y_data, train_size=0.8)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=3)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=3)\n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lToUu5NnCe6X"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch % params['step_size'] == 0 and epoch != 0:\n",
        "        return lr * params['gamma']\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1pvvOT86FEO",
        "outputId": "71df6b19-a177-485a-e9b2-bf285a4c1ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "169/255 [==================>...........] - ETA: 15s - loss: 1.1527 - accuracy: 0.3960 - f1_metric: 0.1960 - precision_2: 0.4449 - recall_2: 0.1010"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = architectures.ResNet(num_channels=params['num_channels'], num_classes=params['num_classes'], num_resblocks=params['num_resblocks'], opt=params['resblock_id'])\n",
        "optimizer = Adam(learning_rate=params['learning_rate'],  weight_decay=params['weight_decay'])\n",
        "\n",
        "precision = Precision()\n",
        "recall = Recall()\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    precision_value = precision(y_true, y_pred)\n",
        "    recall_value = recall(y_true, y_pred)\n",
        "    return  2 * ((precision_value * recall_value) / (precision_value + recall_value +  1e-7))\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', f1_metric, precision, recall])\n",
        "\n",
        "keras.utils.set_random_seed(params[\"seed\"])\n",
        "np.random.seed(params[\"seed\"])\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_data), y=y_data)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], verbose=1, validation_data=(X_test, y_test), class_weight=class_weight_dict)\n",
        "model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], verbose=1, validation_data=(X_test, y_test), class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FK_d2NvG7CK"
      },
      "outputs": [],
      "source": [
        "tflite_quant_model = network_training.get_quantized_model(model)\n",
        "interpreter = network_training.get_tflite_interpreter(tflite_quant_model)\n",
        "quantized_acc, quantized_time, report = network_training.evaluate_quantized_metrics(interpreter, X_test, y_test)\n",
        "\n",
        "print(f\"Quantized model accuracy: {quantized_acc *  100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpDnb8x_JO8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "with open('converted_quant_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "non_quantized_model_size = os.path.getsize('non_quantized_model.h5') / float(2**20)\n",
        "print(f\"Non-quantized model size: {non_quantized_model_size} MB\")\n",
        "\n",
        "quantized_model_size = os.path.getsize('converted_quant_model.tflite') / float(2**20)\n",
        "print(f\"Quantized model size: {quantized_model_size} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-BKreiD5vTA"
      },
      "outputs": [],
      "source": [
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# for i in range(len(X_test)):\n",
        "#     input_data = X_test[i].reshape(input_shape)\n",
        "#     model.predict(input_data, verbose=0)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "non_quantized_time = time.time() - start_time\n",
        "print(f\"Non-quantized model inference time: {non_quantized_time} seconds\")\n",
        "\n",
        "print(f\"Quantized model inference time: {quantized_time} seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}