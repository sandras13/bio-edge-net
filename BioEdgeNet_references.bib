
@inproceedings{bustos_predicting_2021,
	address = {Nara, Japan},
	title = {Predicting {Driver} {Self}-{Reported} {Stress} by {Analyzing} the {Road} {Scene}},
	isbn = {978-1-66540-019-0},
	url = {https://ieeexplore.ieee.org/document/9597438/},
	doi = {10.1109/ACII52823.2021.9597438},
	urldate = {2023-10-24},
	booktitle = {2021 9th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} ({ACII})},
	publisher = {IEEE},
	author = {Bustos, Cristina and Elhaouij, Neska and Sole-Ribalta, Albert and Borge-Holthoefer, Javier and Lapedriza, Agata and Picard, Rosalind},
	month = sep,
	year = {2021},
	pages = {1--8},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\HUH737IV\\Bustos et al. - 2021 - Predicting Driver Self-Reported Stress by Analyzin.pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780459/},
	doi = {10.1109/CVPR.2016.90},
	urldate = {2023-10-24},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\EADSHLS3\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2023-10-24},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv:1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\3ECK96QR\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\UWFC9R7E\\1502.html:text/html},
}

@inproceedings{haouij_affectiveroad_2018,
	address = {Pau France},
	title = {{AffectiveROAD} system and database to assess driver's attention},
	isbn = {978-1-4503-5191-1},
	url = {https://dl.acm.org/doi/10.1145/3167132.3167395},
	doi = {10.1145/3167132.3167395},
	language = {en},
	urldate = {2023-10-24},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Haouij, Neska El and Poggi, Jean-Michel and Sevestre-Ghalila, Sylvie and Ghozi, Raja and Jaïdane, Mériem},
	month = apr,
	year = {2018},
	pages = {800--803},
}

@article{dissanayake_sigrep_2022,
	title = {{SigRep}: {Toward} {Robust} {Wearable} {Emotion} {Recognition} {With} {Contrastive} {Representation} {Learning}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {{SigRep}},
	url = {https://ieeexplore.ieee.org/document/9706192/},
	doi = {10.1109/ACCESS.2022.3149509},
	urldate = {2023-10-26},
	journal = {IEEE Access},
	author = {Dissanayake, Vipula and Seneviratne, Sachith and Rana, Rajib and Wen, Elliott and Kaluarachchi, Tharindu and Nanayakkara, Suranga},
	year = {2022},
	pages = {18105--18120},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\T6QCTY4H\\Dissanayake et al. - 2022 - SigRep Toward Robust Wearable Emotion Recognition.pdf:application/pdf},
}

@inproceedings{siirtola_continuous_2019,
	address = {London United Kingdom},
	title = {Continuous stress detection using the sensors of commercial smartwatch},
	isbn = {978-1-4503-6869-8},
	url = {https://dl.acm.org/doi/10.1145/3341162.3344831},
	doi = {10.1145/3341162.3344831},
	language = {en},
	urldate = {2023-10-26},
	booktitle = {Adjunct {Proceedings} of the 2019 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2019 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Siirtola, Pekka},
	month = sep,
	year = {2019},
	pages = {1198--1201},
}

@article{amin_real-world_2023,
	title = {Real-{World} {Driver} {Stress} {Recognition} and {Diagnosis} {Based} on {Multimodal} {Deep} {Learning} and {Fuzzy} {EDAS} {Approaches}},
	volume = {13},
	issn = {2075-4418},
	url = {https://www.mdpi.com/2075-4418/13/11/1897},
	doi = {10.3390/diagnostics13111897},
	abstract = {Mental stress is known as a prime factor in road crashes. The devastation of these crashes often results in damage to humans, vehicles, and infrastructure. Likewise, persistent mental stress could lead to the development of mental, cardiovascular, and abdominal disorders. Preceding research in this domain mostly focuses on feature engineering and conventional machine learning approaches. These approaches recognize different levels of stress based on handcrafted features extracted from various modalities including physiological, physical, and contextual data. Acquiring good quality features from these modalities using feature engineering is often a difficult job. Recent developments in the form of deep learning (DL) algorithms have relieved feature engineering by automatically extracting and learning resilient features. This paper proposes different CNN and CNN-LSTSM-based fusion models using physiological signals (SRAD dataset) and multimodal data (AffectiveROAD dataset) for the driver’s two and three stress levels. The fuzzy EDAS (evaluation based on distance from average solution) approach is used to evaluate the performance of the proposed models based on different classification metrics (accuracy, recall, precision, F-score, and specificity). Fuzzy EDAS performance estimation shows that the proposed CNN and hybrid CNN-LSTM models achieved the first ranks based on the fusion of BH, E4-Left (E4-L), and E4-Right (E4-R). Results showed the significance of multimodal data for designing an accurate and trustworthy stress recognition diagnosing model for real-world driving conditions. The proposed model can also be used for the diagnosis of the stress level of a subject during other daily life activities.},
	language = {en},
	number = {11},
	urldate = {2023-10-26},
	journal = {Diagnostics},
	author = {Amin, Muhammad and Ullah, Khalil and Asif, Muhammad and Shah, Habib and Mehmood, Arshad and Khan, Muhammad Attique},
	month = may,
	year = {2023},
	pages = {1897},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\JPYXHGMM\\Amin et al. - 2023 - Real-World Driver Stress Recognition and Diagnosis.pdf:application/pdf},
}

@article{siirtola_comparison_2020,
	title = {Comparison of {Regression} and {Classification} {Models} for {User}-{Independent} and {Personal} {Stress} {Detection}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/16/4402},
	doi = {10.3390/s20164402},
	abstract = {In this article, regression and classification models are compared for stress detection. Both personal and user-independent models are experimented. The article is based on publicly open dataset called AffectiveROAD, which contains data gathered using Empatica E4 sensor and unlike most of the other stress detection datasets, it contains continuous target variables. The used classification model is Random Forest and the regression model is Bagged tree based ensemble. Based on experiments, regression models outperform classification models, when classifying observations as stressed or not-stressed. The best user-independent results are obtained using a combination of blood volume pulse and skin temperature features, and using these the average balanced accuracy was 74.1\% with classification model and 82.3\% using regression model. In addition, regression models can be used to estimate the level of the stress. Moreover, the results based on models trained using personal data are not encouraging showing that biosignals have a lot of variation not only between the study subjects but also between the session gathered from the same person. On the other hand, it is shown that with subject-wise feature selection for user-independent model, it is possible to improve recognition models more than by using personal training data to build personal models. In fact, it is shown that with subject-wise feature selection, the average detection rate can be improved as much as 4\%-units, and it is especially useful to reduce the variance in the recognition rates between the study subjects.},
	language = {en},
	number = {16},
	urldate = {2023-10-26},
	journal = {Sensors},
	author = {Siirtola, Pekka and Röning, Juha},
	month = aug,
	year = {2020},
	pages = {4402},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\J8A3AP28\\Siirtola and Röning - 2020 - Comparison of Regression and Classification Models.pdf:application/pdf},
}

@inproceedings{lopez-martinez_detection_2019,
	address = {Cambridge, United Kingdom},
	title = {Detection of {Real}-{World} {Driving}-{Induced} {Affective} {State} {Using} {Physiological} {Signals} and {Multi}-{View} {Multi}-{Task} {Machine} {Learning}},
	isbn = {978-1-72813-891-6},
	url = {https://ieeexplore.ieee.org/document/8925190/},
	doi = {10.1109/ACIIW.2019.8925190},
	urldate = {2023-12-20},
	booktitle = {2019 8th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	publisher = {IEEE},
	author = {Lopez-Martinez, Daniel and El-Haouij, Neska and Picard, Rosalind},
	month = sep,
	year = {2019},
	pages = {356--361},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\U5WEMQZL\\Lopez-Martinez et al. - 2019 - Detection of Real-World Driving-Induced Affective .pdf:application/pdf},
}

@inproceedings{szegedy_going_2015,
	address = {Boston, MA, USA},
	title = {Going deeper with convolutions},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298594/},
	doi = {10.1109/CVPR.2015.7298594},
	urldate = {2023-12-20},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
	pages = {1--9},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\R37QI3RA\\Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf},
}

@article{ghamari_review_2018,
	title = {A review on wearable photoplethysmography sensors and their potential future applications in health care},
	volume = {4},
	issn = {25732838},
	url = {https://medcraveonline.com/IJBSBE/a-review-on-wearable-photoplethysmography-sensors-and-their-potential-future-applications-in-health-care.html},
	doi = {10.15406/ijbsbe.2018.04.00125},
	number = {4},
	urldate = {2024-05-18},
	journal = {International Journal of Biosensors \& Bioelectronics},
	author = {Ghamari, Mohammad},
	year = {2018},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\QU7E5KA2\\Ghamari - 2018 - A review on wearable photoplethysmography sensors .pdf:application/pdf},
}

@misc{springenberg_striving_2015,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2024-05-30},
	publisher = {arXiv},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = apr,
	year = {2015},
	note = {arXiv:1412.6806 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\ARTKCY2P\\Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\XRAGLLMM\\1412.html:text/html},
}

@misc{jacob_quantization_2017,
	title = {Quantization and {Training} of {Neural} {Networks} for {Efficient} {Integer}-{Arithmetic}-{Only} {Inference}},
	url = {http://arxiv.org/abs/1712.05877},
	abstract = {The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs.},
	urldate = {2024-06-04},
	publisher = {arXiv},
	author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
	month = dec,
	year = {2017},
	note = {arXiv:1712.05877 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\QY2QVKW2\\Jacob et al. - 2017 - Quantization and Training of Neural Networks for E.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\ZAZPXASK\\1712.html:text/html},
}

@misc{tan_efficientnet_2020,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://arxiv.org/abs/1905.11946},
	abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Tan, Mingxing and Le, Quoc V.},
	month = sep,
	year = {2020},
	note = {arXiv:1905.11946 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\R3YS6FH5\\Tan and Le - 2020 - EfficientNet Rethinking Model Scaling for Convolu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\RD2GQND7\\1905.html:text/html},
}

@misc{howard_mobilenets_2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	shorttitle = {{MobileNets}},
	url = {http://arxiv.org/abs/1704.04861},
	abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	month = apr,
	year = {2017},
	note = {arXiv:1704.04861 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\BXVNPV3I\\Howard et al. - 2017 - MobileNets Efficient Convolutional Neural Network.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\4T9HS4YC\\1704.html:text/html},
}

@article{saha_machine_2022,
	title = {Machine {Learning} for {Microcontroller}-{Class} {Hardware}: {A} {Review}},
	volume = {22},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1530-437X, 1558-1748, 2379-9153},
	shorttitle = {Machine {Learning} for {Microcontroller}-{Class} {Hardware}},
	url = {https://ieeexplore.ieee.org/document/9912325/},
	doi = {10.1109/JSEN.2022.3210773},
	number = {22},
	urldate = {2024-07-30},
	journal = {IEEE Sensors Journal},
	author = {Saha, Swapnil Sayan and Sandha, Sandeep Singh and Srivastava, Mani},
	month = nov,
	year = {2022},
	pages = {21362--21390},
	file = {Accepted Version:C\:\\Users\\Sandra\\Zotero\\storage\\F7II3777\\Saha et al. - 2022 - Machine Learning for Microcontroller-Class Hardwar.pdf:application/pdf},
}

@article{diab_embedded_2022,
	title = {Embedded {Machine} {Learning} {Using} {Microcontrollers} in {Wearable} and {Ambulatory} {Systems} for {Health} and {Care} {Applications}: {A} {Review}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Embedded {Machine} {Learning} {Using} {Microcontrollers} in {Wearable} and {Ambulatory} {Systems} for {Health} and {Care} {Applications}},
	url = {https://ieeexplore.ieee.org/document/9893137/},
	doi = {10.1109/ACCESS.2022.3206782},
	urldate = {2024-07-30},
	journal = {IEEE Access},
	author = {Diab, Maha S. and Rodriguez-Villegas, Esther},
	year = {2022},
	pages = {98450--98474},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\LGP54WTZ\\Diab and Rodriguez-Villegas - 2022 - Embedded Machine Learning Using Microcontrollers i.pdf:application/pdf},
}

@article{alessandrini_recurrent_2021,
	title = {Recurrent {Neural} {Network} for {Human} {Activity} {Recognition} in {Embedded} {Systems} {Using} {PPG} and {Accelerometer} {Data}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/10/14/1715},
	doi = {10.3390/electronics10141715},
	abstract = {Photoplethysmography (PPG) is a common and practical technique to detect human activity and other physiological parameters and is commonly implemented in wearable devices. However, the PPG signal is often severely corrupted by motion artifacts. The aim of this paper is to address the human activity recognition (HAR) task directly on the device, implementing a recurrent neural network (RNN) in a low cost, low power microcontroller, ensuring the required performance in terms of accuracy and low complexity. To reach this goal, (i) we first develop an RNN, which integrates PPG and tri-axial accelerometer data, where these data can be used to compensate motion artifacts in PPG in order to accurately detect human activity; (ii) then, we port the RNN to an embedded device, Cloud-JAM L4, based on an STM32 microcontroller, optimizing it to maintain an accuracy of over 95\% while requiring modest computational power and memory resources. The experimental results show that such a system can be effectively implemented on a constrained-resource system, allowing the design of a fully autonomous wearable embedded system for human activity recognition and logging.},
	language = {en},
	number = {14},
	urldate = {2024-07-30},
	journal = {Electronics},
	author = {Alessandrini, Michele and Biagetti, Giorgio and Crippa, Paolo and Falaschetti, Laura and Turchetti, Claudio},
	month = jul,
	year = {2021},
	pages = {1715},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\HIX7YTJ6\\Alessandrini et al. - 2021 - Recurrent Neural Network for Human Activity Recogn.pdf:application/pdf},
}

@article{hnoohom_physical_2023,
	title = {Physical {Activity} {Recognition} {Based} on {Deep} {Learning} {Using} {Photoplethysmography} and {Wearable} {Inertial} {Sensors}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/3/693},
	doi = {10.3390/electronics12030693},
	abstract = {Human activity recognition (HAR) extensively uses wearable inertial sensors since this data source provides the most information for non-visual datasets’ time series. HAR research has advanced significantly in recent years due to the proliferation of wearable devices with sensors. To improve recognition performance, HAR researchers have extensively investigated other sources of biosignals, such as a photoplethysmograph (PPG), for this task. PPG sensors measure the rate at which blood flows through the body, and this rate is regulated by the heart’s pumping action, which constantly occurs throughout the body. Even though detecting body movement and gestures was not initially the primary purpose of PPG signals, we propose an innovative method for extracting relevant features from the PPG signal and use deep learning (DL) to predict physical activities. To accomplish the purpose of our study, we developed a deep residual network referred to as PPG-NeXt, designed based on convolutional operation, shortcut connections, and aggregated multi-branch transformation to efficiently identify different types of daily life activities from the raw PPG signal. The proposed model achieved more than 90\% prediction F1-score from experimental results using only PPG data on the three benchmark datasets. Moreover, our results indicate that combining PPG and acceleration signals can enhance activity recognition. Although, both biosignals—electrocardiography (ECG) and PPG—can differentiate between stationary activities (such as sitting) and non-stationary activities (such as cycling and walking) with a level of success that is considered sufficient. Overall, our results propose that combining features from the ECG signal can be helpful in situations where pure tri-axial acceleration (3D-ACC) models have trouble differentiating between activities with relative motion (e.g., walking, stair climbing) but significant differences in their heart rate signatures.},
	language = {en},
	number = {3},
	urldate = {2024-07-30},
	journal = {Electronics},
	author = {Hnoohom, Narit and Mekruksavanich, Sakorn and Jitpattanakul, Anuchit},
	month = jan,
	year = {2023},
	pages = {693},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\CD6LB3A8\\Hnoohom et al. - 2023 - Physical Activity Recognition Based on Deep Learni.pdf:application/pdf},
}

@misc{weng_neural_2023,
	title = {Neural {Network} {Quantization} for {Efficient} {Inference}: {A} {Survey}},
	shorttitle = {Neural {Network} {Quantization} for {Efficient} {Inference}},
	url = {http://arxiv.org/abs/2112.06126},
	abstract = {As neural networks have become more powerful, there has been a rising desire to deploy them in the real world; however, the power and accuracy of neural networks is largely due to their depth and complexity, making them difficult to deploy, especially in resource-constrained devices. Neural network quantization has recently arisen to meet this demand of reducing the size and complexity of neural networks by reducing the precision of a network. With smaller and simpler networks, it becomes possible to run neural networks within the constraints of their target hardware. This paper surveys the many neural network quantization techniques that have been developed in the last decade. Based on this survey and comparison of neural network quantization techniques, we propose future directions of research in the area.},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Weng, Olivia},
	month = jan,
	year = {2023},
	note = {arXiv:2112.06126 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\LIGUYFU5\\Weng - 2023 - Neural Network Quantization for Efficient Inferenc.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\9LY5HSXH\\2112.html:text/html},
}

@misc{nagel_up_2020,
	title = {Up or {Down}? {Adaptive} {Rounding} for {Post}-{Training} {Quantization}},
	shorttitle = {Up or {Down}?},
	url = {http://arxiv.org/abs/2004.10568},
	abstract = {When quantizing neural networks, assigning each floating-point weight to its nearest fixed-point value is the predominant approach. We find that, perhaps surprisingly, this is not the best we can do. In this paper, we propose AdaRound, a better weight-rounding mechanism for post-training quantization that adapts to the data and the task loss. AdaRound is fast, does not require fine-tuning of the network, and only uses a small amount of unlabelled data. We start by theoretically analyzing the rounding problem for a pre-trained neural network. By approximating the task loss with a Taylor series expansion, the rounding task is posed as a quadratic unconstrained binary optimization problem. We simplify this to a layer-wise local loss and propose to optimize this loss with a soft relaxation. AdaRound not only outperforms rounding-to-nearest by a significant margin but also establishes a new state-of-the-art for post-training quantization on several networks and tasks. Without fine-tuning, we can quantize the weights of Resnet18 and Resnet50 to 4 bits while staying within an accuracy loss of 1\%.},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Nagel, Markus and Amjad, Rana Ali and van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
	month = jun,
	year = {2020},
	note = {arXiv:2004.10568 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\JYSQRGPW\\Nagel et al. - 2020 - Up or Down Adaptive Rounding for Post-Training Qu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\UFMARJGJ\\2004.html:text/html},
}

@inproceedings{zhuang_towards_2018,
	address = {Salt Lake City, UT},
	title = {Towards {Effective} {Low}-{Bitwidth} {Convolutional} {Neural} {Networks}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578924/},
	doi = {10.1109/CVPR.2018.00826},
	urldate = {2024-07-30},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Zhuang, Bohan and Shen, Chunhua and Tan, Mingkui and Liu, Lingqiao and Reid, Ian},
	month = jun,
	year = {2018},
	pages = {7920--7928},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\RSVEDELN\\Zhuang et al. - 2018 - Towards Effective Low-Bitwidth Convolutional Neura.pdf:application/pdf},
}

@misc{sandler_mobilenetv2_2019,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	shorttitle = {{MobileNetV2}},
	url = {http://arxiv.org/abs/1801.04381},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. The MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	month = mar,
	year = {2019},
	note = {arXiv:1801.04381 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\XRPHEP5K\\Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\BCMMQQ57\\1801.html:text/html},
}

@inproceedings{chollet_xception_2017,
	address = {Honolulu, HI},
	title = {Xception: {Deep} {Learning} with {Depthwise} {Separable} {Convolutions}},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Xception},
	url = {http://ieeexplore.ieee.org/document/8099678/},
	doi = {10.1109/CVPR.2017.195},
	urldate = {2024-08-03},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Chollet, Francois},
	month = jul,
	year = {2017},
	pages = {1800--1807},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\7UIVPJ2N\\Chollet - 2017 - Xception Deep Learning with Depthwise Separable C.pdf:application/pdf},
}

@article{guo_depthwise_2019,
	title = {Depthwise {Convolution} {Is} {All} {You} {Need} for {Learning} {Multiple} {Visual} {Domains}},
	volume = {33},
	copyright = {https://www.aaai.org},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4851},
	doi = {10.1609/aaai.v33i01.33018368},
	abstract = {There is a growing interest in designing models that can deal with images from different visual domains. If there exists a universal structure in different visual domains that can be captured via a common parameterization, then we can use a single model for all domains rather than one model per domain. A model aware of the relationships between different domains can also be trained to work on new domains with less resources. However, to identify the reusable structure in a model is not easy. In this paper, we propose a multi-domain learning architecture based on depthwise separable convolution. The proposed approach is based on the assumption that images from different domains share cross-channel correlations but have domain-specific spatial correlations. The proposed model is compact and has minimal overhead when being applied to new domains. Additionally, we introduce a gating mechanism to promote soft sharing between different domains. We evaluate our approach on Visual Decathlon Challenge, a benchmark for testing the ability of multi-domain models. The experiments show that our approach can achieve the highest score while only requiring 50\% of the parameters compared with the state-of-the-art approaches.},
	number = {01},
	urldate = {2024-08-03},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Guo, Yunhui and Li, Yandong and Wang, Liqiang and Rosing, Tajana},
	month = jul,
	year = {2019},
	pages = {8368--8375},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\YPZ4K4PX\\Guo et al. - 2019 - Depthwise Convolution Is All You Need for Learning.pdf:application/pdf},
}

@misc{lin_network_2014,
	title = {Network {In} {Network}},
	url = {http://arxiv.org/abs/1312.4400},
	abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
	month = mar,
	year = {2014},
	note = {arXiv:1312.4400 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\AUYVGZJP\\Lin et al. - 2014 - Network In Network.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\6T6JPRAU\\1312.html:text/html},
}

@misc{gholami_survey_2021,
	title = {A {Survey} of {Quantization} {Methods} for {Efficient} {Neural} {Network} {Inference}},
	url = {http://arxiv.org/abs/2103.13630},
	abstract = {As soon as abstract mathematical computations were adapted to computation on digital computers, the problem of efficient representation, manipulation, and communication of the numerical values in those computations arose. Strongly related to the problem of numerical representation is the problem of quantization: in what manner should a set of continuous real-valued numbers be distributed over a fixed discrete set of numbers to minimize the number of bits required and also to maximize the accuracy of the attendant computations? This perennial problem of quantization is particularly relevant whenever memory and/or computational resources are severely restricted, and it has come to the forefront in recent years due to the remarkable performance of Neural Network models in computer vision, natural language processing, and related areas. Moving from floating-point representations to low-precision fixed integer values represented in four bits or less holds the potential to reduce the memory footprint and latency by a factor of 16x; and, in fact, reductions of 4x to 8x are often realized in practice in these applications. Thus, it is not surprising that quantization has emerged recently as an important and very active sub-area of research in the efficient implementation of computations associated with Neural Networks. In this article, we survey approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. With this survey and its organization, we hope to have presented a useful snapshot of the current research in quantization for Neural Networks and to have given an intelligent organization to ease the evaluation of future research in this area.},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
	month = jun,
	year = {2021},
	note = {arXiv:2103.13630 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\XULCTTBJ\\Gholami et al. - 2021 - A Survey of Quantization Methods for Efficient Neu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\W55K3G7N\\2103.html:text/html},
}

@article{rokh_comprehensive_2023,
	title = {A {Comprehensive} {Survey} on {Model} {Quantization} for {Deep} {Neural} {Networks} in {Image} {Classification}},
	volume = {14},
	issn = {2157-6904, 2157-6912},
	url = {http://arxiv.org/abs/2205.07877},
	doi = {10.1145/3623402},
	abstract = {Recent advancements in machine learning achieved by Deep Neural Networks (DNNs) have been significant. While demonstrating high accuracy, DNNs are associated with a huge number of parameters and computations, which leads to high memory usage and energy consumption. As a result, deploying DNNs on devices with constrained hardware resources poses significant challenges. To overcome this, various compression techniques have been widely employed to optimize DNN accelerators. A promising approach is quantization, in which the full-precision values are stored in low bit-width precision. Quantization not only reduces memory requirements but also replaces high-cost operations with low-cost ones. DNN quantization offers flexibility and efficiency in hardware design, making it a widely adopted technique in various methods. Since quantization has been extensively utilized in previous works, there is a need for an integrated report that provides an understanding, analysis, and comparison of different quantization approaches. Consequently, we present a comprehensive survey of quantization concepts and methods, with a focus on image classification. We describe clustering-based quantization methods and explore the use of a scale factor parameter for approximating full-precision values. Moreover, we thoroughly review the training of a quantized DNN, including the use of a straight-through estimator and quantization regularization. We explain the replacement of floating-point operations with low-cost bitwise operations in a quantized DNN and the sensitivity of different layers in quantization. Furthermore, we highlight the evaluation metrics for quantization methods and important benchmarks in the image classification task. We also present the accuracy of the state-of-the-art methods on CIFAR-10 and ImageNet.},
	number = {6},
	urldate = {2024-08-03},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Rokh, Babak and Azarpeyvand, Ali and Khanteymoori, Alireza},
	month = dec,
	year = {2023},
	note = {arXiv:2205.07877 [cs]},
	keywords = {Computer Science - Machine Learning, A.1},
	pages = {1--50},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\P6LGNKR4\\Rokh et al. - 2023 - A Comprehensive Survey on Model Quantization for D.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\5TIE3DS8\\2205.html:text/html},
}

@misc{krishnamoorthi_quantizing_2018,
	title = {Quantizing deep convolutional networks for efficient inference: {A} whitepaper},
	shorttitle = {Quantizing deep convolutional networks for efficient inference},
	url = {http://arxiv.org/abs/1806.08342},
	abstract = {We present an overview of techniques for quantizing convolutional neural networks for inference with integer weights and activations. Per-channel quantization of weights and per-layer quantization of activations to 8-bits of precision post-training produces classification accuracies within 2\% of floating point networks for a wide variety of CNN architectures. Model sizes can be reduced by a factor of 4 by quantizing weights to 8-bits, even when 8-bit arithmetic is not supported. This can be achieved with simple, post training quantization of weights.We benchmark latencies of quantized networks on CPUs and DSPs and observe a speedup of 2x-3x for quantized implementations compared to floating point on CPUs. Speedups of up to 10x are observed on specialized processors with fixed point SIMD capabilities, like the Qualcomm QDSPs with HVX. Quantization-aware training can provide further improvements, reducing the gap to floating point to 1\% at 8-bit precision. Quantization-aware training also allows for reducing the precision of weights to four bits with accuracy losses ranging from 2\% to 10\%, with higher accuracy drop for smaller networks.We introduce tools in TensorFlow and TensorFlowLite for quantizing convolutional networks and review best practices for quantization-aware training to obtain high accuracy with quantized weights and activations. We recommend that per-channel quantization of weights and per-layer quantization of activations be the preferred quantization scheme for hardware acceleration and kernel optimization. We also propose that future processors and hardware accelerators for optimized inference support precisions of 4, 8 and 16 bits.},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Krishnamoorthi, Raghuraman},
	month = jun,
	year = {2018},
	note = {arXiv:1806.08342 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\64SSYKAN\\Krishnamoorthi - 2018 - Quantizing deep convolutional networks for efficie.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\6CXAM5RV\\1806.html:text/html},
}

@article{biagetti_dataset_2020,
	title = {Dataset from {PPG} wireless sensor for activity monitoring},
	volume = {29},
	issn = {23523409},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352340919314003},
	doi = {10.1016/j.dib.2019.105044},
	language = {en},
	urldate = {2024-08-03},
	journal = {Data in Brief},
	author = {Biagetti, Giorgio and Crippa, Paolo and Falaschetti, Laura and Saraceni, Leonardo and Tiranti, Andrea and Turchetti, Claudio},
	month = apr,
	year = {2020},
	pages = {105044},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\DBE9A6DP\\Biagetti et al. - 2020 - Dataset from PPG wireless sensor for activity moni.pdf:application/pdf},
}

@misc{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv:1711.05101 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\JJS64NSN\\Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\J6QJTK9M\\1711.html:text/html},
}

@article{singh_comparative_2013,
	title = {A comparative evaluation of neural network classifiers for stress level analysis of automotive drivers using physiological signals},
	volume = {8},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809413000992},
	doi = {10.1016/j.bspc.2013.06.014},
	language = {en},
	number = {6},
	urldate = {2024-08-04},
	journal = {Biomedical Signal Processing and Control},
	author = {Singh, Rajiv Ranjan and Conjeti, Sailesh and Banerjee, Rahul},
	month = nov,
	year = {2013},
	pages = {740--754},
}

@article{salehin_review_2023,
	title = {A {Review} on {Dropout} {Regularization} {Approaches} for {Deep} {Neural} {Networks} within the {Scholarly} {Domain}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/14/3106},
	doi = {10.3390/electronics12143106},
	abstract = {Dropout is one of the most popular regularization methods in the scholarly domain for preventing a neural network model from overfitting in the training phase. Developing an effective dropout regularization technique that complies with the model architecture is crucial in deep learning-related tasks because various neural network architectures have been proposed, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs), and they have exhibited reasonable performance in their specialized areas. In this paper, we provide a comprehensive and novel review of the state-of-the-art (SOTA) in dropout regularization. We explain various dropout methods, from standard random dropout to AutoDrop dropout (from the original to the advanced), and also discuss their performance and experimental capabilities. This paper provides a summary of the latest research on various dropout regularization techniques for achieving improved performance through “Internal Structure Changes”, “Data Augmentation”, and “Input Information”. We can see that proper regularization with respect to structural constraints of network architecture is a critical factor to facilitate overfitting avoidance. We discuss the strengths and limitations of the methods presented in this work, which can serve as valuable references for future research and the development of new approaches. We also pay attention to the scholarly domain in the discussion in order to meet the overwhelming increase of scientific research outcomes by providing an analysis of several important academic scholarly issues of neural networks.},
	language = {en},
	number = {14},
	urldate = {2024-08-04},
	journal = {Electronics},
	author = {Salehin, Imrus and Kang, Dae-Ki},
	month = jul,
	year = {2023},
	pages = {3106},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\S6N4W3BV\\Salehin and Kang - 2023 - A Review on Dropout Regularization Approaches for .pdf:application/pdf},
}

@article{rahma_electrodermal_2022,
	title = {Electrodermal activity for measuring cognitive and emotional stress level},
	volume = {12},
	issn = {2228-7477},
	url = {https://journals.lww.com/10.4103/jmss.JMSS_78_20},
	doi = {10.4103/jmss.JMSS_78_20},
	language = {en},
	number = {2},
	urldate = {2024-08-04},
	journal = {Journal of Medical Signals \& Sensors},
	author = {Rahma, OsmalinaNur and Putra, AlfianPramudita and Rahmatillah, Akif and Putri, YangSa'ada Kamila Ariyansah and Fajriaty, NuzulaDwi and Ain, Khusnul and Chai, Rifai},
	year = {2022},
	pages = {155},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\BH5IIXK9\\Rahma et al. - 2022 - Electrodermal activity for measuring cognitive and.pdf:application/pdf},
}

@article{zhao_identification_2023,
	title = {Identification of psychological stress states based on joint analysis of multidomain features of skin conductance},
	volume = {86},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809423007103},
	doi = {10.1016/j.bspc.2023.105277},
	language = {en},
	urldate = {2024-08-04},
	journal = {Biomedical Signal Processing and Control},
	author = {Zhao, Lanjun and Wang, Xinpei and Wang, Duanwei and Jiao, Yu and Dong, Huiwen and Du, Guanzheng and Liu, Yuanyuan and Li, Yuanyang and Liu, Changchun},
	month = sep,
	year = {2023},
	pages = {105277},
}

@article{zhang_reaction_2017,
	title = {Reaction time and physiological signals for stress recognition},
	volume = {38},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809417300885},
	doi = {10.1016/j.bspc.2017.05.003},
	language = {en},
	urldate = {2024-08-04},
	journal = {Biomedical Signal Processing and Control},
	author = {Zhang, Bo and Morère, Yann and Sieler, Loïc and Langlet, Cécile and Bolmont, Benoît and Bourhis, Guy},
	month = sep,
	year = {2017},
	pages = {100--107},
}

@article{tanwar_attention_2024,
	title = {Attention based hybrid deep learning model for wearable based stress recognition},
	volume = {127},
	issn = {09521976},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197623015750},
	doi = {10.1016/j.engappai.2023.107391},
	language = {en},
	urldate = {2024-08-04},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Tanwar, Ritu and Phukan, Orchid Chetia and Singh, Ghanapriya and Pal, Pankaj Kumar and Tiwari, Sanju},
	month = jan,
	year = {2024},
	pages = {107391},
}

@misc{xu_fits_2024,
	title = {{FITS}: {Modeling} {Time} {Series} with \$10k\$ {Parameters}},
	shorttitle = {{FITS}},
	url = {http://arxiv.org/abs/2307.03756},
	abstract = {In this paper, we introduce FITS, a lightweight yet powerful model for time series analysis. Unlike existing models that directly process raw time-domain data, FITS operates on the principle that time series can be manipulated through interpolation in the complex frequency domain. By discarding high-frequency components with negligible impact on time series data, FITS achieves performance comparable to state-of-the-art models for time series forecasting and anomaly detection tasks, while having a remarkably compact size of only approximately \$10k\$ parameters. Such a lightweight model can be easily trained and deployed in edge devices, creating opportunities for various applications. The code is available in: {\textbackslash}url\{https://github.com/VEWOXIC/FITS\}},
	urldate = {2024-08-13},
	publisher = {arXiv},
	author = {Xu, Zhijian and Zeng, Ailing and Xu, Qiang},
	month = jan,
	year = {2024},
	note = {arXiv:2307.03756 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\66AV4JVD\\Xu et al. - 2024 - FITS Modeling Time Series with \$10k\$ Parameters.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\YHVGYJSB\\2307.html:text/html},
}

@inproceedings{iandola_small_2017,
	address = {Seoul Republic of Korea},
	title = {Small neural nets are beautiful: enabling embedded systems with small deep-neural-network architectures},
	isbn = {978-1-4503-5185-0},
	shorttitle = {Small neural nets are beautiful},
	url = {https://dl.acm.org/doi/10.1145/3125502.3125606},
	doi = {10.1145/3125502.3125606},
	language = {en},
	urldate = {2024-08-18},
	booktitle = {Proceedings of the {Twelfth} {IEEE}/{ACM}/{IFIP} {International} {Conference} on {Hardware}/{Software} {Codesign} and {System} {Synthesis} {Companion}},
	publisher = {ACM},
	author = {Iandola, Forrest and Keutzer, Kurt},
	month = oct,
	year = {2017},
	pages = {1--10},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\U8Q6H2C6\\Iandola and Keutzer - 2017 - Small neural nets are beautiful enabling embedded.pdf:application/pdf},
}

@article{liu_lightweight_2024,
	title = {Lightweight {Deep} {Learning} for {Resource}-{Constrained} {Environments}: {A} {Survey}},
	volume = {56},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Lightweight {Deep} {Learning} for {Resource}-{Constrained} {Environments}},
	url = {https://dl.acm.org/doi/10.1145/3657282},
	doi = {10.1145/3657282},
	abstract = {Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model’s accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and Large Language Models. Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.},
	language = {en},
	number = {10},
	urldate = {2024-08-18},
	journal = {ACM Computing Surveys},
	author = {Liu, Hou-I and Galindo, Marco and Xie, Hongxia and Wong, Lai-Kuan and Shuai, Hong-Han and Li, Yung-Hui and Cheng, Wen-Huang},
	month = oct,
	year = {2024},
	pages = {1--42},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\Y9XEH8ZL\\Liu et al. - 2024 - Lightweight Deep Learning for Resource-Constrained.pdf:application/pdf},
}
